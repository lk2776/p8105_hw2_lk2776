p8105_hw2_lk2776
================
2024-09-30

``` r
#load packages
library(tidyverse)
```

## problem1:

``` r
#read data using read_csv() from tidyverse
nyc_data = read_csv("./data/NYC_Transit_Subway_Entrance_And_Exit_Data.csv", 
                    na=c("NA",".",""), 
                    col_names = TRUE, 
                    col_types = cols(
                      Route8=col_character(),
                      Route9=col_character(), 
                      Route10=col_character(),
                      Route11=col_character())) |>
  #clean column names
  janitor::clean_names() |> 
  #select columns 
  select(line,station_name,station_latitude,station_longitude,
         entry,vending,entrance_type,ada,
         route1,route2,route3,route4,route5,
         route6,route7,route8,route9,route10,route11
         ) |> 
  #convert entry column from character to logical vector
  mutate(entry=if_else(entry %in%"YES",TRUE,FALSE))

#check class of columns of dataset to verify entry varible class
nyc_data |> sapply(class)
```

    ##              line      station_name  station_latitude station_longitude 
    ##       "character"       "character"         "numeric"         "numeric" 
    ##             entry           vending     entrance_type               ada 
    ##         "logical"       "character"       "character"         "logical" 
    ##            route1            route2            route3            route4 
    ##       "character"       "character"       "character"       "character" 
    ##            route5            route6            route7            route8 
    ##       "character"       "character"       "character"       "character" 
    ##            route9           route10           route11 
    ##       "character"       "character"       "character"

The cleaning process of NYC dataset involved reading the data with
missing values using na(), specifying columns route8-11 as character
columns using col_types(), cleaning the column names with
janitor::clean_names(), selecting the desired columns with select(), and
converting the entry variable using mutate() and ifelse() functions. The
data is not tidy because routes1-11 can be put together in two columns:
route_name and route_value. The resulting dataset has the following
number of rows and columns: **\[1,868 x 19\]** . It contains the
following variables: **line, station_name, station_latitude,
station_longitude, entry, vending, entrance_type, ada, route1, route2,
route3, route4, route5, route6, route7, route8, route9, route10,
route11**

- number of distinct stations in the dataset. :**465**

- number of stations are ada compliant. **468**

- ~38% proportion of stations with vending allow entrance

- 91 distinct stations serve the A train after data is reformatted so
  that route number and name are distinct variables.

- of the 91 distinct stations that serve the A train, only 34 stations
  are ADA compliant.

``` r
#proportion of stations with entry but with out vending
#table(nyc_data$vending) #183 NO
nyc_data |> select(entry, vending) |> 
  filter(vending %in% "NO") |>
  table()
```

    ##        vending
    ## entry    NO
    ##   FALSE 114
    ##   TRUE   69

``` r
69/183
```

    ## [1] 0.3770492

``` r
#number of distinct stations with route "A"
nyc_data |> pivot_longer(
  route1:route11, 
  names_to="route_number",
  values_to="route_name"
) |>
  filter(route_name == "A") |> 
  unite("line_station_name", line:station_name) |> 
  n_distinct()
```

    ## [1] 91

``` r
#number of distinct stations with route "A" and ada compliant
nyc_data |> pivot_longer(
  route1:route11, 
  names_to="route_number",
  values_to="route_name"
) |>
  filter(route_name == "A") |> 
  filter(ada=="TRUE") |> 
unite("line_station_name", line:station_name) |> 
  n_distinct()
```

    ## [1] 34

## problem 2

``` r
#read mr_trash_wheel data
mr_trash_wheel = readxl::read_excel("./data/202409_Trash_Wheel_Collection_Data.xlsx",
                            sheet = "Mr. Trash Wheel", 
                            col_names=TRUE,na="") |>
  #remove empty columns 
  select(-"...15",-"...16") |>
  #clean names
  janitor::clean_names() |>
  #drop rows with empty dumpster values
  drop_na(dumpster) |> 
  #convert sports balls to integer and round it off
  mutate(sports_balls = as.integer(round(sports_balls),digits=0)) |>
  #create a new variable
  mutate(wheel_name = "mr_trash_wheel")
```

    ## New names:
    ## • `` -> `...15`
    ## • `` -> `...16`

``` r
#read professor trash wheel data
prof_trash_wheel = readxl::read_excel("./data/202409_Trash_Wheel_Collection_Data.xlsx",
                            sheet = "Professor Trash Wheel", col_names=TRUE,na="") |>
  #clean names
  janitor::clean_names() |>
  #drop rows with empty dumpster values
  drop_na(dumpster) |> 
  #convert year to character for bindin purposes
  mutate(year=as.character(year)) |> 
  #create new variable
  mutate(wheel_name = "prof_trash_wheel")

#read gwynnda data 
g_trash_wheel = readxl::read_excel("./data/202409_Trash_Wheel_Collection_Data.xlsx",
                            sheet = "Gwynnda Trash Wheel", col_names=TRUE,na="") |>
  #clean names 
  janitor::clean_names() |>
  #drop rows with empty dumpster values 
  drop_na(dumpster) |>
  #convert year to character for bindin purposes
  mutate(year=as.character(year)) |> 
  #create new variable
  mutate(wheel_name = "g_trash_wheel")

#combine tables 
trash_wheel_tidy = 
  bind_rows(mr_trash_wheel, prof_trash_wheel, g_trash_wheel) 
```

Mr. Trash Wheel data is read using read_csv(). Empty columns are
deselected using select(), and a new variable, wheel_name, is created
with the value ‘mr_trash_wheel’ using mutate(). The values in the
‘sports_balls’ column are rounded to the nearest integer, and rows that
do not include dumpster-specific data are omitted. Professor Trash Wheel
and Gwynnda data are cleaned and read in a similar manner, with a new
variable, wheel_name, added to them with the values ‘prof_trash_wheel’
and ‘g_trash_wheel,’ respectively. The variable year is converted to
character class for these two datasets to facilitate binding with other
datasets.

The number of rows and columns of mr. trash wheel dataset are: : **\[651
x 15\]**

The number of rows and columns of prof. trash wheel dataset are: :
**\[119 x 14\]**

The number of rows and columns of gywn. trash wheel dataset are: :
**\[263 x 13\]**

The number of rows and columns of the combined dataset are : **1033,
15**

Column names of the combined trashwheel datasets are: **dumpster, month,
year, date, weight_tons, volume_cubic_yards, plastic_bottles,
polystyrene, cigarette_butts, glass_bottles, plastic_bags, wrappers,
sports_balls, homes_powered, wheel_name**

The weight in tons of trash collected by professor trash wheel:
**246.74**

The total number of cigarette butts collected by Gwynnda trash wheel in
2022 are 205410

``` r
#number of cigarette butts collected by g_trash_wheel in 2022
g_trash_wheel |>  filter(year%in%"2022")  |>
  summarize(sum_cig_butts = sum(cigarette_butts, na.rm=TRUE))
```

    ## # A tibble: 1 × 1
    ##   sum_cig_butts
    ##           <dbl>
    ## 1        205410

additional information:

Mr. Trash Wheel collected the most trash in tons according to the
dataset

The weight in tons of trash collected by mr. trash wheel: **2091.18**

The weight in tons of trash collected by prof. trash wheel: **246.74**

The weight in tons of trash collected by gwynnda trash wheel: **797.55**

Cigarette butts: Mr. Trash Wheel collected the highest number of
cigarette butts according to the dataset.

The total number of cigarette_butts collected by mr.trash wheel:
**1.18067^{7}**

The total number of cigarette_butts collected by prof trash wheel:
**1.277478^{6}**

The total number of cigarette_butts collected by gwynndatrash wheel:
**6.2392^{5}**

Plastic bottles: Mr. Trash Wheel collected the highest number of plastic
bottles according to the dataset.

The total number of plastic_bottles collected by mr.trash wheel:
**1.280075^{6}**

The total number of plastic_bottles collected by prof trash wheel:
**5.93246^{5}**

The total number of plastic_bottles collected by gwynndatrash wheel:
**3.96227^{5}**

## problem3

``` r
bakers_data = read_csv("./data/bakers.csv", 
                       col_names=TRUE,
                       na=c("NA",".","")) |>
  janitor::clean_names() |>
  separate(baker_name,into=c("baker","rest_of_the_name"), sep=" ", remove=FALSE) |>
  select(-rest_of_the_name)
```

    ## Rows: 120 Columns: 5
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr (3): Baker Name, Baker Occupation, Hometown
    ## dbl (2): Series, Baker Age
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

``` r
bakes_data = read_csv("./data/bakes.csv", 
                      col_names=TRUE,
                      na=c("NA",".","")) |> 
  janitor::clean_names() 
```

    ## Rows: 548 Columns: 5
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr (3): Baker, Signature Bake, Show Stopper
    ## dbl (2): Series, Episode
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

``` r
#join the datasets by full_join
bakers_bakes_df = 
  full_join(bakers_data, bakes_data, by = c("baker", "series")) |>
  relocate(baker_name,baker,baker_age,baker_occupation,hometown,series,episode,signature_bake,show_stopper)

#check for completeness and correctness of data
head(anti_join(bakers_data, bakes_data, by = c("baker", "series")))
```

    ## # A tibble: 6 × 6
    ##   baker_name          baker  series baker_age baker_occupation  hometown 
    ##   <chr>               <chr>   <dbl>     <dbl> <chr>             <chr>    
    ## 1 Alice Fevronia      Alice      10        28 Geography teacher Essex    
    ## 2 Amelia LeBruin      Amelia     10        24 Fashion designer  Halifax  
    ## 3 Antony Amourdoux    Antony      9        30 Banker            London   
    ## 4 Briony Williams     Briony      9        33 Full-time parent  Bristol  
    ## 5 Dan Beasley-Harling Dan         9        36 Full-time parent  London   
    ## 6 Dan Chambers        Dan        10        32 Support worker    Rotherham

``` r
head(anti_join(bakes_data, bakers_data, by = c("baker", "series")))
```

    ## # A tibble: 6 × 5
    ##   series episode baker    signature_bake                            show_stopper
    ##    <dbl>   <dbl> <chr>    <chr>                                     <chr>       
    ## 1      2       1 "\"Jo\"" Chocolate Orange CupcakesOrange and Card… Chocolate a…
    ## 2      2       2 "\"Jo\"" Caramelised Onion, Gruyere and Thyme Qui… Raspberry a…
    ## 3      2       3 "\"Jo\"" Stromboli flavored with Mozzarella, Ham,… Unknown     
    ## 4      2       4 "\"Jo\"" Lavender Biscuits                         Blueberry M…
    ## 5      2       5 "\"Jo\"" Salmon and Asparagus Pie                  Apple and R…
    ## 6      2       6 "\"Jo\"" Rum and Raisin Baked Cheesecake           Limoncello …

``` r
#read results data 
results_data = read_csv("./data/results.csv", 
                        col_names=TRUE,
                        na=c("NA",".",""), skip=2) |>
  janitor::clean_names() 
```

    ## Rows: 1136 Columns: 5
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr (2): baker, result
    ## dbl (3): series, episode, technical
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

``` r
#join results data with bakers_bakes_df
bakers_bakes_results_df = 
full_join(bakers_bakes_df, results_data, by=c("baker","series","episode"))
write_csv(bakers_bakes_results_df,file="./data/bakers_bakes_results_df.csv")

#check for completeness of data
head(anti_join(bakers_bakes_df, results_data, by = c("baker","series","episode")))
```

    ## # A tibble: 6 × 9
    ##   baker_name          baker  baker_age baker_occupation  hometown series episode
    ##   <chr>               <chr>      <dbl> <chr>             <chr>     <dbl>   <dbl>
    ## 1 Alice Fevronia      Alice         28 Geography teacher Essex        10      NA
    ## 2 Amelia LeBruin      Amelia        24 Fashion designer  Halifax      10      NA
    ## 3 Antony Amourdoux    Antony        30 Banker            London        9      NA
    ## 4 Briony Williams     Briony        33 Full-time parent  Bristol       9      NA
    ## 5 Dan Beasley-Harling Dan           36 Full-time parent  London        9      NA
    ## 6 Dan Chambers        Dan           32 Support worker    Rotherh…     10      NA
    ## # ℹ 2 more variables: signature_bake <chr>, show_stopper <chr>

``` r
head(anti_join(results_data, bakers_bakes_df,by = c("baker","series","episode")))
```

    ## # A tibble: 6 × 5
    ##   series episode baker   technical result
    ##    <dbl>   <dbl> <chr>       <dbl> <chr> 
    ## 1      1       2 Lea            NA <NA>  
    ## 2      1       2 Mark           NA <NA>  
    ## 3      1       3 Annetha        NA <NA>  
    ## 4      1       3 Lea            NA <NA>  
    ## 5      1       3 Louise         NA <NA>  
    ## 6      1       3 Mark           NA <NA>

``` r
#read viewers_df
viewers_df = read_csv("./data/viewers.csv", 
                        col_names=TRUE,
                        na=c("NA",".","")) |>
  janitor::clean_names() 
```

    ## Rows: 10 Columns: 11
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## dbl (11): Episode, Series 1, Series 2, Series 3, Series 4, Series 5, Series ...
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

Bakers data is read using read_csv() from the tidyverse, and the column
names are cleaned using janitor::clean_names(). A ‘baker’ variable is
created from the first part of the baker_name variable using separate(),
while the ‘rest_of_the_name’ is removed from the dataset. This
additional variable is created to facilitate a join with bakes_data,
which contains only the ‘baker’ variable (not the full name).

Bakes data is read in a similar fashion and joined with bakers_data
using full_join(). Similarly, results_data is read using read_csv(),
skipping the first two lines of the dataset, and then joined with
bakers_bakes_data using full_join(). The anti_join() function is used to
verify that no data is missed while joining the tables.

One of the questions I addressed was whether to skip the lines in
results.csv using code or to manually delete those lines in Excel. I
chose to use skip = 2 to skip the lines in results.csv. Another question
was which join to use; I decided on full_join() to ensure that no data
from the dataframes is missed.

The no. of rows and columns of final dataset are: **1170, 11**

The variables of the final dataset are: **baker_name, baker, baker_age,
baker_occupation, hometown, series, episode, signature_bake,
show_stopper, technical, result**

Following table showing the star baker or winnder from seasons 5 to 10.
If a baker scored high on techical, they are more likely to win a star
baker or winner.

``` r
#create a table for starbaker/winner for each episode in season 5 to 10
table = bakers_bakes_results_df |>  filter(result==c("WINNER","STAR BAKER")) |>
  filter(series >= 5) |>
  arrange(series,episode) |> 
  select(baker_name, baker, series, episode, technical, result)
head(table)
```

    ## # A tibble: 6 × 6
    ##   baker_name        baker   series episode technical result    
    ##   <chr>             <chr>    <dbl>   <dbl>     <dbl> <chr>     
    ## 1 Nancy Birtwhistle Nancy        5       1         1 STAR BAKER
    ## 2 Kate Henry        Kate         5       5         3 STAR BAKER
    ## 3 Richard Burr      Richard      5       7         1 STAR BAKER
    ## 4 Richard Burr      Richard      5       9         2 STAR BAKER
    ## 5 Nancy Birtwhistle Nancy        5      10         1 WINNER    
    ## 6 Marie Campbell    Marie        6       1         3 STAR BAKER

The viewers data:

``` r
viewers_df[1:10,1:11] 
```

    ## # A tibble: 10 × 11
    ##    episode series_1 series_2 series_3 series_4 series_5 series_6 series_7
    ##      <dbl>    <dbl>    <dbl>    <dbl>    <dbl>    <dbl>    <dbl>    <dbl>
    ##  1       1     2.24     3.1      3.85     6.6      8.51     11.6     13.6
    ##  2       2     3        3.53     4.6      6.65     8.79     11.6     13.4
    ##  3       3     3        3.82     4.53     7.17     9.28     12.0     13.0
    ##  4       4     2.6      3.6      4.71     6.82    10.2      12.4     13.3
    ##  5       5     3.03     3.83     4.61     6.95     9.95     12.4     13.1
    ##  6       6     2.75     4.25     4.82     7.32    10.1      12       13.1
    ##  7       7    NA        4.42     5.1      7.76    10.3      12.4     13.4
    ##  8       8    NA        5.06     5.35     7.41     9.02     11.1     13.3
    ##  9       9    NA       NA        5.7      7.41    10.7      12.6     13.4
    ## 10      10    NA       NA        6.74     9.45    13.5      15.0     15.9
    ## # ℹ 3 more variables: series_8 <dbl>, series_9 <dbl>, series_10 <dbl>

The average viewership in season 1 is: **2.77**

The average viewership in season 5 is: **10.04**
